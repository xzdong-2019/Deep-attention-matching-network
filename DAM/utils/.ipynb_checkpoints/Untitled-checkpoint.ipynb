{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import operations as op\n",
    "import layers\n",
    "from tensorflow.keras.layers import Conv1D,GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named douban_evalutaion",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8c9b9c894570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouban_evalutaion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named douban_evalutaion"
     ]
    }
   ],
   "source": [
    "import utils.douban_evalutaion as eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 30, 40]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x  = tf.placeholder(tf.float32,shape=[10,30,40])\n",
    "input_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= [1,2,3,4,5]\n",
    "x[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'global_max_pooling1d_1/Max:0' shape=(10, 128) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Conv1D(filters=128, kernel_size=5, activation='relu')(input_x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def attention(\n",
    "    Q, K, V, \n",
    "    Q_lengths, K_lengths, \n",
    "    attention_type='dot', \n",
    "    is_mask=True, mask_value=-2**32+1,\n",
    "    drop_prob=None):\n",
    "    '''Add attention layer.\n",
    "    Args:\n",
    "        Q: a tensor with shape [batch, Q_time, Q_dimension]\n",
    "        K: a tensor with shape [batch, time, K_dimension]\n",
    "        V: a tensor with shape [batch, time, V_dimension]\n",
    "\n",
    "        Q_length: a tensor with shape [batch]\n",
    "        K_length: a tensor with shape [batch]\n",
    "\n",
    "    Returns:\n",
    "        a tensor with shape [batch, Q_time, V_dimension]\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: if\n",
    "            Q_dimension not equal to K_dimension when attention type is dot.\n",
    "    '''\n",
    "    assert attention_type in ('dot', 'bilinear')\n",
    "    if attention_type == 'dot':\n",
    "        assert Q.shape[-1] == K.shape[-1]\n",
    "\n",
    "    Q_time = Q.shape[1]\n",
    "    K_time = K.shape[1]\n",
    "\n",
    "    if attention_type == 'dot':\n",
    "        logits = op.dot_sim(Q, K) #[batch, Q_time, time]\n",
    "    if attention_type == 'bilinear':\n",
    "        logits = op.bilinear_sim(Q, K)\n",
    "\n",
    "    if is_mask:\n",
    "        mask = op.mask(Q_lengths, K_lengths, Q_time, K_time) #[batch, Q_time, K_time]\n",
    "        logits = mask * logits + (1 - mask) * mask_value\n",
    "    \n",
    "    attention = tf.nn.softmax(logits)\n",
    "\n",
    "    if drop_prob is not None:\n",
    "        print('use attention drop')\n",
    "        attention = tf.nn.dropout(attention, drop_prob)\n",
    "\n",
    "    return op.weighted_sum(attention, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    '''attention(Q, K, V) = softmax(Q * K^T / sqrt(dk)) * V'''\n",
    "    # query 和 Key相乘\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    # 使用dk进行缩放\n",
    "    dk = tf.cast(tf.shape(q)[-1], tf.float32)\n",
    "    scaled_attention =matmul_qk / tf.sqrt(dk)\n",
    "    # 掩码mask\n",
    "    if mask is not None:\n",
    "        # 这里将mask的token乘以-1e-9，这样与attention相加后，mask的位置经过softmax后就为0\n",
    "        # padding位置 mask=1\n",
    "        scaled_attention += mask * -1e-9\n",
    "    # 通过softmax获取attention权重, mask部分softmax后为0\n",
    "    attention_weights = tf.nn.softmax(scaled_attention)  # shape=[batch_size, seq_len_q, seq_len_k]\n",
    "    # 乘以value\n",
    "    outputs = tf.matmul(attention_weights, v)  # shape=[batch_size, seq_len_q, depth]\n",
    "    return outputs, attention_weights\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        # d_model必须可以正确分成多个头\n",
    "        assert d_model % num_heads == 0\n",
    "        # 分头之后维度\n",
    "        self.depth = d_model // num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # 分头，将头个数的维度，放到seq_len前面 x输入shape=[batch_size, seq_len, d_model]\n",
    "        x = tf.reshape(x, [batch_size, -1, self.num_heads, self.depth])\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        # 分头前的前向网络，根据q,k,v的输入，计算Q, K, V语义\n",
    "        q = self.wq(q)  # shape=[batch_size, seq_len_q, d_model]\n",
    "        k = self.wq(k)\n",
    "        v = self.wq(v)\n",
    "        # 分头\n",
    "        q = self.split_heads(q, batch_size)  # shape=[batch_size, num_heads, seq_len_q, depth]\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        # 通过缩放点积注意力层\n",
    "        # scaled_attention shape=[batch_size, num_heads, seq_len_q, depth]\n",
    "        # attention_weights shape=[batch_size, num_heads, seq_len_q, seq_len_k]\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        # 把多头维度后移\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) # shape=[batch_size, seq_len_q, num_heads, depth]\n",
    "        # 把多头合并\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model)) # shape=[batch_size, seq_len_q, d_model]\n",
    "        # 全连接重塑\n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "turns_len = 5\n",
    "words = 10\n",
    "dim =10\n",
    "\n",
    "input_turns = tf.placeholder(tf.float32, [2,5,10,10])\n",
    "respones  = tf.placeholder(tf.float32, [batch_size, words, dim])\n",
    "respones_len = tf.placeholder(tf.int32,[batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(2, 5, 10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# input_turns = tf.transpose(input_turns,perm=[1,0,2,3])\n",
    "# input_turns = tf.transpose(input_turns,perm=[1,0,2,3])\n",
    "print(input_turns)\n",
    "_turn_match = []\n",
    "\n",
    "for _t in tf.split(input_turns,5,1):\n",
    "    _t = tf.squeeze(_t)\n",
    "    _match_result= attention(respones, _t,  _t, respones_len, respones_len)\n",
    "    _turn_match.append(tf.expand_dims(_match_result,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_11:0' shape=(2, 5, 10, 10) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_turn_match = tf.concat(_turn_match,1)\n",
    "best_turn_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead = MultiHeadAttention(dim,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FFN(x, out_dimension_0=None, out_dimension_1=None):\n",
    "    '''Add two dense connected layer, max(0, x*W0+b0)*W1+b1.\n",
    "\n",
    "    Args:\n",
    "        x: a tensor with shape [batch, time, dimension]\n",
    "        out_dimension: a number which is the output dimension\n",
    "\n",
    "    Returns:\n",
    "        a tensor with shape [batch, time, out_dimension]\n",
    "\n",
    "    Raises:\n",
    "    '''\n",
    "    with tf.variable_scope('FFN_1'):\n",
    "        y = op.dense(x, out_dimension_0)\n",
    "        y = tf.nn.relu(y)\n",
    "    with tf.variable_scope('FFN_2'):\n",
    "        z = op.dense(y, out_dimension_1) #, add_bias=False)  #!!!!\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'multi_head_attention_1/dense_3/BiasAdd:0' shape=(2, 10, 10) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result,_ = multihead(respones, best_turn_match, best_turn_match)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = FFN(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'FFN_2/add:0' shape=(2, 10, 10) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
