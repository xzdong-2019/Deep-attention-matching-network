{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bin.test_and_evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = Dense(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_normal_1:0' shape=(2, 3, 4, 20) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random_normal([2,3,4,20])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(2, 3, 4, 32) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = dense(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2dict = {}\n",
    "with open('./data/douban/word2id_douban_utf-8','r') as fr:\n",
    "        for line in fr.readlines():\n",
    "#           print(line)\n",
    "          _word_num = line.strip().split()\n",
    "          word2dict[_word_num[0]] = _word_num[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    \"data_path\": \"./data/douban/data.pkl\",\n",
    "    \"save_path\": \"./output/douban/DAM_hireaction/\",\n",
    "    \"word_emb_init\": \"./data/douban/word_embedding.pkl\",\n",
    "    # \"data_path\": \"./data/ubuntu/data.pkl\",\n",
    "    # \"save_path\": \"./output/ubuntu/DAM_new/\",\n",
    "    # \"word_emb_init\": \"./data/ubuntu/word_embedding.pkl\",\n",
    "    # \"init_model\": None,  #should be set for test  \"output/douban/temp/model.ckpt.18\"\n",
    "\n",
    "    \"init_model\": \"output/douban/DAM_hireaction/model.ckpt.18\",  #should be set for test  \"output/douban/temp/model.ckpt.18\"\n",
    "    \"rand_seed\": None, \n",
    "\n",
    "    \"drop_dense\": None,\n",
    "    \"drop_attention\": None,\n",
    "\n",
    "    \"is_mask\": True,\n",
    "    \"is_layer_norm\": True,\n",
    "    \"is_positional\": False,  \n",
    "\n",
    "    \"stack_num\": 5,  \n",
    "    \"attention_type\": \"dot\",\n",
    "\n",
    "    \"learning_rate\": 1e-3,\n",
    "    #\"vocab_size\": 434512, #for ubuntu\n",
    "    \"vocab_size\": 172130, #for douban\n",
    "    \"emb_size\": 200,\n",
    "    \"batch_size\": 200, #200 for test\n",
    "\n",
    "    \"max_turn_num\": 2,  \n",
    "    \"max_turn_len\": 50, \n",
    "\n",
    "    \"max_to_keep\": 1,\n",
    "    \"num_scan_data\": 2,\n",
    "    #\"_EOS_\": 28270, #for ubuntu data\n",
    "    \"_EOS_\": 1, #1 for douban data\n",
    "    \"final_n_class\": 1,\n",
    "    \"max_turn_history_num\":5,\n",
    "    \"head_nums\":4,\n",
    "}\n",
    "\n",
    "train_data, val_data, test_data = pickle.load(open(conf[\"data_path\"], 'rb'))\n",
    "# test_data = load_data('./data/douban/test.txt', word2dict)\n",
    "\n",
    "# test_batches = build_batches(test_data, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6670"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['y'][0:10]\n",
    "len(test_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['y'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['y'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
